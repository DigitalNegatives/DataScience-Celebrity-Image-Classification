{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from utils.celeb import *\n",
    "from utils.dataset import *\n",
    "from utils.reporting import *\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import IPython.display as ipyd\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data_dir = \"/home/data/images/\"\n",
    "#log_dir = \"/home/logs/\"\n",
    "\n",
    "data_dir = \"../data/MsCelebV1-Faces-Cropped.Samples/\"\n",
    "log_dir = \"./test/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_entities = 4\n",
    "n_images = 10\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./utils/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./utils/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a df\n",
      "I have images and labels\n"
     ]
    }
   ],
   "source": [
    "df = get_dataframe(data_dir, n_entities, n_images, rnd_seed=seed)\n",
    "print('I have a df')\n",
    "all_images, all_labels = get_all_images(df, data_dir)\n",
    "print('I have images and labels')\n",
    "all_images = np.ravel(all_images).reshape(all_images.shape[0], all_images.shape[1] * all_images.shape[2] * all_images.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset init\n"
     ]
    }
   ],
   "source": [
    "split = [0.8, 0.0, 0.2]\n",
    "ds = Dataset(all_images, all_labels, split=split, one_hot=True, rnd_seed=seed)\n",
    "\n",
    "n_samples = ds.X.shape[0]\n",
    "n_features = ds.X.shape[1]\n",
    "n_classes = ds.Y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Input placeholders\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, n_classes], name='y-input')\n",
    "\n",
    "with tf.name_scope('input_reshape'):\n",
    "    #x_4d = tf.reshape(x, [-1, 50, 50, 3])\n",
    "    x_4d = tf.reshape(x, [-1, 100, 100, 3])\n",
    "    tf.summary.image('input', x_4d, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Variables for Weights and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We can't initialize these variables to 0 - the network will get stuck.\n",
    "\n",
    "def weight_variable_xavier(name, shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.get_variable(\n",
    "                            name=name,\n",
    "                            shape=shape,\n",
    "                            initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    return initial\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, strides=[1,1,1,1]):\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x, ksize, strides):\n",
    "    return tf.nn.max_pool(x, ksize=ksize,\n",
    "                        strides=strides, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#X must be 4D\n",
    "#def convolutions(X, n_input_chs, n_filters, filter_sizes, filter_strides, activation=tf.nn.relu):\n",
    "def convolutions(X, n_filters, filter_sizes, filter_strides, activation=tf.nn.relu):\n",
    "    current_in = X\n",
    "    n_input_chs = X.get_shape().as_list()[3]\n",
    "    Ws = []\n",
    "    shapes = []\n",
    "\n",
    "    # Build the encoder\n",
    "    for layer_i, n_output_chs in enumerate(n_filters):\n",
    "        with tf.variable_scope('convolution/{}'.format(layer_i)):\n",
    "            shapes.append(current_in.get_shape().as_list())\n",
    "            W = weight_variable_xavier(\n",
    "                                name = \"W{}\".format(layer_i),\n",
    "                                shape = [filter_sizes[layer_i], \n",
    "                                 filter_sizes[layer_i], \n",
    "                                 n_input_chs, n_output_chs])\n",
    "            \n",
    "            h = conv2d(current_in, W, filter_strides)\n",
    "            h = activation(h)\n",
    "            Ws.append(W)\n",
    "            current_in = h\n",
    "            n_input_chs = n_output_chs\n",
    "            print(\"h.shape:\", h.get_shape().as_list())\n",
    "    shapes.append(current_in.get_shape().as_list())\n",
    "    print(\"shapes:\",shapes)\n",
    "    return h, Ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Summaries for all var to include min/max/mean/std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    if (len(input_tensor.get_shape().as_list())==4):\n",
    "        input_shape = input_tensor.get_shape().as_list()\n",
    "        input_tensor = tf.reshape(input_tensor, [-1, input_shape[1]*input_shape[2]*input_shape[3]])\n",
    "    \n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "      # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "            tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "        tf.summary.histogram('activations', activations)\n",
    "        return activations, preactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_layer(h, dropout):\n",
    "    with tf.name_scope('dropout'):\n",
    "        #keep_prob = tf.placeholder(tf.float32)\n",
    "        #tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "        tf.summary.scalar('dropout_keep_probability', dropout)\n",
    "        dropped = tf.nn.dropout(h, dropout)\n",
    "    return dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data_dir = \"/home/data/images/\"\n",
    "#log_dir = \"/home/logs/\"\n",
    "learning_rate = 0.003\n",
    "epochs = 100\n",
    "dropout = 0.8\n",
    "FC_only = False\n",
    "\n",
    "#Conv parameters\n",
    "n_filters = [32, 32, 8]  #filter output sizes\n",
    "filter_sizes = [4, 4, 2]  #\n",
    "filter_strides = [1, 2, 2, 1]\n",
    "#maxpool parameters\n",
    "ksize = [1,2,2,1]\n",
    "k_strides = [1,2,2,1]\n",
    "#FC parameter\n",
    "final_layer = [n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.shape: [None, 50, 50, 32]\n",
      "h.shape: [None, 25, 25, 32]\n",
      "h.shape: [None, 13, 13, 8]\n",
      "shapes: [[None, 100, 100, 3], [None, 50, 50, 32], [None, 25, 25, 32], [None, 13, 13, 8]]\n",
      "h.shape: [None, 13, 13, 8]\n",
      "h[3]: 8\n",
      "Ws: [<tensorflow.python.ops.variables.Variable object at 0x110fad390>, <tensorflow.python.ops.variables.Variable object at 0x127e86358>, <tensorflow.python.ops.variables.Variable object at 0x127e86940>]\n"
     ]
    }
   ],
   "source": [
    "if not FC_only:\n",
    "    h, Ws = convolutions(x_4d, n_filters, filter_sizes, filter_strides)\n",
    "    h_shape = h.get_shape().as_list()\n",
    "    print(\"h.shape:\", h.get_shape().as_list())\n",
    "    print(\"h[3]:\", h.get_shape().as_list()[3])\n",
    "    print(\"Ws:\", Ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Make a FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#hidden1 = nn_layer(h, h, 500, 'layer1')\n",
    "hidden1, pre_act_1 = nn_layer(h, h_shape[1]*h_shape[2]*h_shape[3], 100, 'layer1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"layer1/activation:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Drop layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do not apply softmax activation yet, see below.\n",
    "#dropped = drop_layer(hidden1)\n",
    "#y = nn_layer(hidden1, 100, n_classes, 'layer2', act=tf.identity)\n",
    "\n",
    "dropped = drop_layer(hidden1, dropout)\n",
    "y, pre_act_2 = nn_layer(dropped, 100, n_classes, 'layer2', act=tf.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross entropy cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    with tf.name_scope('total'):\n",
    "        cross_entropy = tf.reduce_mean(diff)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feed data to feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def feed_dict(train):\n",
    "    \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
    "    #if train or FLAGS.fake_data:\n",
    "        #xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n",
    "        #k = FLAGS.dropout\n",
    "    if train:\n",
    "        xs, ys = ds.train.images, ds.train.labels\n",
    "        k = dropout\n",
    "    else:    \n",
    "        xs, ys = ds.test.images, ds.test.labels\n",
    "        k = 1.0\n",
    "    #return {x: xs, y_: ys, keep_prob: k}\n",
    "    return {x: xs, y_: ys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Summary writer and Create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Merge all the summaries and write them out to /tmp/tensorflow/mnist/logs/mnist_with_summaries (by default)\n",
    "merged = tf.summary.merge_all()\n",
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options,\n",
    "        allow_soft_placement=True, log_device_placement=True))  \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(log_dir + '/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy at step 0: 0.25\n",
      "Train accuracy at step 10: 0.9375\n",
      "Train accuracy at step 20: 1.0\n",
      "Train accuracy at step 30: 1.0\n",
      "Train accuracy at step 40: 1.0\n",
      "Train accuracy at step 50: 1.0\n",
      "Train accuracy at step 60: 1.0\n",
      "Train accuracy at step 70: 1.0\n",
      "Train accuracy at step 80: 1.0\n",
      "Train accuracy at step 90: 1.0\n",
      "Test Accuracy: 0.5\n",
      "\n",
      "Train Class Distribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3\n",
       "distribution  9  9  7  7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Class Distribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0  1  2  3\n",
       "distribution  1  1  3  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prec ovall</th>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall overall</th>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 overall</th>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 value\n",
       "prec ovall       0.688\n",
       "recall overall   0.667\n",
       "f1 overall       0.517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results by Class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prec</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3\n",
       "prec    0.25  0.500  1.000  1.000\n",
       "recall  1.00  1.000  0.333  0.333\n",
       "f1      0.40  0.667  0.500  0.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "finalRepresentations = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        # Train accuracy report\n",
    "        summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(True))\n",
    "        train_writer.add_summary(summary, i)\n",
    "        print('Train accuracy at step %s: %s' % (i, acc))\n",
    "        finalRepresentations.append(pre_act_2.eval(session=sess, feed_dict=feed_dict(True)))\n",
    "    else:\n",
    "        # Train network\n",
    "        for batch_X, batch_Y in ds.train.next_batch(batch_size=batch_size):\n",
    "            \n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={x: batch_X, y_: batch_Y})\n",
    "            train_writer.add_summary(summary, i)\n",
    "\n",
    "test_hash = feed_dict(False)\n",
    "summary, acc, y = sess.run([merged, accuracy, y], feed_dict=feed_dict(False))\n",
    "test_writer.add_summary(summary, i)\n",
    "print('Test Accuracy: %s' % (acc))\n",
    "\n",
    "report(y, ds, n_classes)\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
