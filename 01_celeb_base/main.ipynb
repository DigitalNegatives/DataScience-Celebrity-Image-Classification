{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from utils.celeb import *\n",
    "from utils.load_preprocessed import *\n",
    "from utils.dataset import *\n",
    "from utils.reporting import *\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import IPython.display as ipyd\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_base_dir = \"../data/crop_4_20\"\n",
    "corpus_dir = \"{}/corpus\".format(data_base_dir)\n",
    "bottleneck_dir = \"{}/bottleneck\".format(data_base_dir)\n",
    "\n",
    "log_dir = \"./test/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_cascade_dir = './utils/haarcascade_frontalface_default.xml'\n",
    "eye_cascade_dir = './utils/haarcascade_eye.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "#data_dir = \"/home/data/images/\"\n",
    "#log_dir = \"/home/logs/\"\n",
    "learning_rate = 0.003\n",
    "epochs = 100\n",
    "# dropout = 0.8\n",
    "dropout_train = 0.75\n",
    "dropout_test = 1.0\n",
    "FC_only = False\n",
    "\n",
    "#Conv parameters\n",
    "n_filters = [32, 32, 8]  #filter output sizes\n",
    "filter_sizes = [4, 4, 2]  #\n",
    "filter_strides = [1, 2, 2, 1]\n",
    "#maxpool parameters\n",
    "ksize = [1,2,2,1]\n",
    "k_strides = [1,2,2,1]\n",
    "#FC parameter\n",
    "n_nodes = 100\n",
    "# final_layer = [n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_images_4d, all_labels, _ = load_preprocessed_data(corpus_dir, \n",
    "                                            bottleneck_dir)\n",
    "x_4d_shape = all_images_4d.shape\n",
    "all_images = np.ravel(all_images_4d).reshape(all_images_4d.shape[0], \n",
    "        all_images_4d.shape[1] * all_images_4d.shape[2] * all_images_4d.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset init\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 100, 100, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = [0.8, 0.0, 0.2]\n",
    "ds = Dataset(all_images, all_labels, split=split, one_hot=True, rnd_seed=seed)\n",
    "\n",
    "n_samples = ds.X.shape[0]\n",
    "n_features = ds.X.shape[1]\n",
    "n_classes = ds.Y.shape[1]\n",
    "train_mean = np.mean(ds.train.images,0)\n",
    "\n",
    "x_4d_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Input placeholders\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, n_classes], name='y-input')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob-input')\n",
    "\n",
    "with tf.name_scope('input_reshape'):\n",
    "    x_4d = tf.reshape(x, [-1, x_4d_shape[1], x_4d_shape[2], x_4d_shape[3]])\n",
    "    tf.summary.image('input', x_4d, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Variables for Weights and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We can't initialize these variables to 0 - the network will get stuck.\n",
    "\n",
    "def weight_variable_xavier(name, shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.get_variable(\n",
    "                            name=name,\n",
    "                            shape=shape,\n",
    "                            initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    return initial\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"Create a weight variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"Create a bias variable with appropriate initialization.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, strides=[1,1,1,1]):\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x, ksize, strides):\n",
    "    return tf.nn.max_pool(x, ksize=ksize,\n",
    "                        strides=strides, padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Summaries for all var to include min/max/mean/std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#X must be 4D\n",
    "def convolutions(X, n_filters, filter_sizes, filter_strides, activation=tf.nn.relu):\n",
    "    current_in = X\n",
    "    n_input_chs = X.get_shape().as_list()[3]\n",
    "    Ws = []\n",
    "    shapes = []\n",
    "\n",
    "    # Build the encoder\n",
    "    for layer_i, n_output_chs in enumerate(n_filters):\n",
    "        with tf.variable_scope('convolution/{}'.format(layer_i)):\n",
    "            shapes.append(current_in.get_shape().as_list())\n",
    "            W = weight_variable_xavier(\n",
    "                                name = \"W{}\".format(layer_i),\n",
    "                                shape = [filter_sizes[layer_i], \n",
    "                                 filter_sizes[layer_i], \n",
    "                                 n_input_chs, n_output_chs])\n",
    "            \n",
    "            pre_activation = conv2d(current_in, W, filter_strides)\n",
    "            h = activation(pre_activation)\n",
    "            Ws.append(W)\n",
    "            current_in = h\n",
    "            n_input_chs = n_output_chs\n",
    "            print(\"h.shape:\", h.get_shape().as_list())\n",
    "    shapes.append(current_in.get_shape().as_list())\n",
    "    print(\"shapes:\",shapes)\n",
    "    return h, Ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    \"\"\"Reusable code for making a simple neural net layer.\n",
    "    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\n",
    "    It also sets up name scoping so that the resultant graph is easy to read,\n",
    "    and adds a number of summary ops.\n",
    "    \"\"\"\n",
    "    if (len(input_tensor.get_shape().as_list())==4):\n",
    "        input_shape = input_tensor.get_shape().as_list()\n",
    "        input_tensor = tf.reshape(input_tensor, [-1, input_shape[1]*input_shape[2]*input_shape[3]])\n",
    "    \n",
    "    # Adding a name scope ensures logical grouping of the layers in the graph.\n",
    "    with tf.name_scope(layer_name):\n",
    "      # This Variable will hold the state of the weights for the layer\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = weight_variable([input_dim, output_dim])\n",
    "            variable_summaries(weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = bias_variable([output_dim])\n",
    "            variable_summaries(biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights) + biases\n",
    "            tf.summary.histogram('pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activation')\n",
    "        tf.summary.histogram('activations', activations)\n",
    "        return activations, preactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def drop_layer(h, keep_prob):\n",
    "    with tf.name_scope('dropout'):\n",
    "        tf.summary.scalar('dropout_keep_probability', keep_prob)\n",
    "        dropped = tf.nn.dropout(h, keep_prob)\n",
    "    return dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.shape: [None, 50, 50, 32]\n",
      "h.shape: [None, 25, 25, 32]\n",
      "h.shape: [None, 13, 13, 8]\n",
      "shapes: [[None, 100, 100, 3], [None, 50, 50, 32], [None, 25, 25, 32], [None, 13, 13, 8]]\n",
      "h.shape: [None, 13, 13, 8]\n",
      "h[3]: 8\n"
     ]
    }
   ],
   "source": [
    "h, Ws = convolutions(x_4d, n_filters, filter_sizes, filter_strides)\n",
    "h_shape = h.get_shape().as_list()\n",
    "print(\"h.shape:\", h.get_shape().as_list())\n",
    "print(\"h[3]:\", h.get_shape().as_list()[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Make a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"layer1/activation:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden1, pre_act_1 = nn_layer(h, h_shape[1]*h_shape[2]*h_shape[3], n_nodes, 'layer1')\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Drop layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dropped = drop_layer(hidden1, keep_prob)\n",
    "hidden2, pre_act_2 = nn_layer(dropped, n_nodes, n_nodes, 'layer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Last fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y, pre_act_3 = nn_layer(hidden2, n_nodes, n_classes, 'layer3', act=tf.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross entropy cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "    with tf.name_scope('total'):\n",
    "        cross_entropy = tf.reduce_mean(diff)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feed data to feed_dict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "def feed_dict(train):\n",
    "    \"\"\"Make a TensorFlow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
    "    if train:\n",
    "        xs, ys = ds.train.images, ds.train.labels\n",
    "        k = dropout\n",
    "    else:    \n",
    "        xs, ys = ds.test.images, ds.test.labels\n",
    "        k = 1.0\n",
    "    #return {x: xs, y_: ys, keep_prob: k}\n",
    "    return {x: xs, y_: ys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Summary writer and Create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Merge all the summaries and write them out to /tmp/tensorflow/mnist/logs/mnist_with_summaries (by default)\n",
    "merged = tf.summary.merge_all()\n",
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options,\n",
    "        allow_soft_placement=True, log_device_placement=True))  \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(log_dir + '/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy at step 0: 0.328125\n",
      "Train accuracy at step 10: 0.421875\n",
      "Train accuracy at step 20: 0.6875\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "finalRepresentations = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        # Train accuracy report\n",
    "        summary, acc, zpre_act_3 = sess.run([merged, accuracy, pre_act_3], feed_dict={x:ds.train.images, \n",
    "                                                                                      y_:ds.train.labels,\n",
    "                                                                                      keep_prob: dropout_test})\n",
    "        train_writer.add_summary(summary, i)\n",
    "        print('Train accuracy at step %s: %s' % (i, acc))\n",
    "        finalRepresentations.append(zpre_act_3)\n",
    "    else:\n",
    "        # Train network\n",
    "        for batch_X, batch_Y in ds.train.next_batch(batch_size=batch_size):\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={x: batch_X, y_: batch_Y, keep_prob: dropout_train})\n",
    "            train_writer.add_summary(summary, i)\n",
    "\n",
    "# test_hash = feed_dict(False)\n",
    "summary, acc, y = sess.run([merged, accuracy, y], feed_dict={x:ds.test.images, y_:ds.test.labels, keep_prob: dropout_test})\n",
    "test_writer.add_summary(summary, i)\n",
    "print('Test Accuracy: %s' % (acc))\n",
    "\n",
    "report(y, ds, n_classes)\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Other Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()\n",
    "[op.name for op in g.get_operations()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pick an image from the test set\n",
    "img_sel = ds.test.images[0]\n",
    "\n",
    "img_conv = np.expand_dims(img_sel, axis=0).astype(np.uint8)\n",
    "print(img_conv.shape)\n",
    "\n",
    "plt.imshow(img_conv.reshape(x_4d_shape[1],x_4d_shape[2],x_4d_shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv_out= g.get_tensor_by_name('convolution/0/Relu:0')\n",
    "img_conv = np.expand_dims(img_sel, axis=0)\n",
    "conv_layer = conv_out.eval(session=sess, feed_dict={x:img_conv})\n",
    "conv_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Activations of the first convolution layer\n",
    "mont_conv = montage_filters(np.rollaxis(np.expand_dims(conv_layer[0], 3), 3, 2))\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(mont_conv, cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reduce the dimensions to two to view how the celeberity images are clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "finalRepresentations[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(perplexity=50, n_components=2, init='pca', n_iter=5000)\n",
    "lowDWeights = tsne.fit_transform(finalRepresentations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_target_idx = np.argmax(ds.train.labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(lowDWeights[:,0], lowDWeights[:,1], c = y_target_idx, cmap=plt.cm.get_cmap('Dark2', n_classes))\n",
    "plt.colorbar(ticks=range(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob.eval(session=sess, feed_dict={keep_prob:0.75})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
